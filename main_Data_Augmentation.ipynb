{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "Generate images using data augmentation (flipping, brightness variation, darkness variation, and salt abnd pepper noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "from skimage.util import random_noise\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - No Plastic',\n",
       " '1 - Little Plastic',\n",
       " '2 - Moderate Plastic',\n",
       " '3 - Lot Plastic']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the rooter path\n",
    "# rooter_path = r'F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp1\\Train 1'\n",
    "rooter_path = r'F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.1-adding_images'\n",
    "\n",
    "folders = os.listdir(rooter_path)\n",
    "folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to store original images and images augmented\n",
    "dst_path_HV = r'F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.4-ANI_DA_HV_ALL'\n",
    "\n",
    "for folder in folders:\n",
    "    srs_dir = rooter_path + '/' + folder\n",
    "    sub_dst_path_HV = dst_path_HV + '/' + folder\n",
    "    files = os.listdir(srs_dir)\n",
    "    for file in files:\n",
    "        img = cv2.imread(srs_dir + '/' + str(file))\n",
    "        ver_img = cv2.flip(img, 0)\n",
    "        hor_img = cv2.flip(img, 1)\n",
    "        hor_ver_img = cv2.flip(img, -1)\n",
    "        # path = sub_dst_path_HV + '/' + str(file).replace('.jpg', '') + '_ver_flip' + '.jpg'\n",
    "        # print(path)\n",
    "        cv2.imwrite(sub_dst_path_HV + '/' + str(file).replace('.jpg', '') + '_ver_flip' + '.jpg', ver_img)\n",
    "        cv2.imwrite(sub_dst_path_HV + '/' + str(file).replace('.jpg', '') + '_hor_flip' + '.jpg', hor_img)\n",
    "        cv2.imwrite(sub_dst_path_HV + '/' + str(file).replace('.jpg', '') + '_hor_ver_flip' + '.jpg', hor_ver_img)\n",
    "        shutil.copyfile(srs_dir + '/' + str(file), sub_dst_path_HV + '/' + str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightness variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to store original images and images augmented\n",
    "dst_path_BR = r'F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train_DA_BR'\n",
    "\n",
    "for folder in folders:\n",
    "    srs_dir = rooter_path + '/' + folder\n",
    "    sub_dst_path_BR = dst_path_BR + '/' + folder\n",
    "    files = os.listdir(srs_dir)\n",
    "    for file in files:\n",
    "        img = Image.open(srs_dir + '/' + str(file))\n",
    "        bright_enhancer = ImageEnhance.Brightness(img)\n",
    "        new_image_1 = bright_enhancer.enhance(random.uniform(1.1, 1.4))\n",
    "        new_image_2 = bright_enhancer.enhance(random.uniform(1.1, 1.4))\n",
    "        new_image_3 = bright_enhancer.enhance(random.uniform(1.1, 1.4))\n",
    "        new_image_1.save(sub_dst_path_BR + '/' + str(file).replace('.jpg', '') + '_bright_1' + '.jpg')\n",
    "        new_image_2.save(sub_dst_path_BR + '/' + str(file).replace('.jpg', '') + '_bright_2' + '.jpg')\n",
    "        new_image_3.save(sub_dst_path_BR + '/' + str(file).replace('.jpg', '') + '_bright_3' + '.jpg')\n",
    "        shutil.copyfile(srs_dir + '/' + str(file), sub_dst_path_BR + '/' + str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Darkness variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to store original images and images augmented\n",
    "dst_path_DARK = r'F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train_DA_DARK'\n",
    "\n",
    "for folder in folders:\n",
    "    srs_dir = rooter_path + '/' + folder\n",
    "    sub_dst_path_DARK = dst_path_DARK + '/' + folder\n",
    "    files = os.listdir(srs_dir)\n",
    "    for file in files:\n",
    "        img = Image.open(srs_dir + '/' + str(file))\n",
    "        bright_enhancer = ImageEnhance.Brightness(img)\n",
    "        new_image_1 = bright_enhancer.enhance(random.uniform(0.6, 0.9))\n",
    "        new_image_2 = bright_enhancer.enhance(random.uniform(0.6, 0.9))\n",
    "        new_image_3 = bright_enhancer.enhance(random.uniform(0.6, 0.9))\n",
    "        new_image_1.save(sub_dst_path_DARK + '/' + str(file).replace('.jpg', '') + '_dark_1' + '.jpg')\n",
    "        new_image_2.save(sub_dst_path_DARK + '/' + str(file).replace('.jpg', '') + '_dark_2' + '.jpg')\n",
    "        new_image_3.save(sub_dst_path_DARK + '/' + str(file).replace('.jpg', '') + '_dark_3' + '.jpg')\n",
    "        shutil.copyfile(srs_dir + '/' + str(file), sub_dst_path_DARK + '/' + str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salt and Pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to store original images and images augmented\n",
    "dst_path_NI = r'F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train_DA_NI'\n",
    "\n",
    "for folder in folders:\n",
    "    srs_dir = rooter_path + '/' + folder\n",
    "    sub_dst_path_NI = dst_path_NI + '/' + folder\n",
    "    files = os.listdir(srs_dir)\n",
    "    for file in files:\n",
    "        img = cv2.imread(srs_dir + '/' + str(file))\n",
    "        noise_img_1 = random_noise(img, mode='s&p', amount=random.uniform(0.01, 0.15))\n",
    "        noise_img_1 = np.array(255*noise_img_1, dtype = 'uint8')\n",
    "        noise_img_2 = random_noise(img, mode='s&p', amount=random.uniform(0.01, 0.15))\n",
    "        noise_img_2 = np.array(255*noise_img_2, dtype          = 'uint8')\n",
    "        noise_img_3 = random_noise(img, mode='s&p', amount=random.uniform(0.01, 0.15))\n",
    "        noise_img_3 = np.array(255*noise_img_3, dtype = 'uint8')\n",
    "        cv2.imwrite(sub_dst_path_NI + '/' + str(file).replace('.jpg', '') + '_noise_1' + '.jpg', noise_img_1)\n",
    "        cv2.imwrite(sub_dst_path_NI + '/' + str(file).replace('.jpg', '') + '_noise_2' + '.jpg', noise_img_2)\n",
    "        cv2.imwrite(sub_dst_path_NI + '/' + str(file).replace('.jpg', '') + '_noise_3' + '.jpg', noise_img_3)\n",
    "        shutil.copyfile(srs_dir + '/' + str(file), sub_dst_path_NI + '/' + str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix four DA methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to store original images and images augmented\n",
    "# dst_path_MIX = r'F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.5-DA MIX'\n",
    "dst_path_MIX = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.2_adding_images_with_DA_MIX\"\n",
    "\n",
    "for folder in folders:\n",
    "    srs_dir = rooter_path + '/' + folder\n",
    "    sub_dst_path_MIX = dst_path_MIX + '/' + folder\n",
    "    files = os.listdir(srs_dir)\n",
    "    for file in files:\n",
    "        \n",
    "        img = cv2.imread(srs_dir + '/' + str(file))\n",
    "        \n",
    "        # flipping\n",
    "        ver_img = cv2.flip(img, 0)\n",
    "        hor_img = cv2.flip(img, 1)\n",
    "        hor_ver_img = cv2.flip(img, -1)\n",
    "        cv2.imwrite(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_ver_flip' + '.jpg', ver_img)\n",
    "        cv2.imwrite(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_hor_flip' + '.jpg', hor_img)\n",
    "        cv2.imwrite(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_hor_ver_flip' + '.jpg', hor_ver_img)\n",
    "     \n",
    "        #  Salt and Pepper noise\n",
    "        noise_img_1 = random_noise(img, mode='s&p', amount=random.uniform(0.01, 0.15))\n",
    "        noise_img_1 = np.array(255*noise_img_1, dtype = 'uint8')\n",
    "        noise_img_2 = random_noise(img, mode='s&p', amount=random.uniform(0.01, 0.15))\n",
    "        noise_img_2 = np.array(255*noise_img_2, dtype          = 'uint8')\n",
    "        noise_img_3 = random_noise(img, mode='s&p', amount=random.uniform(0.01, 0.15))\n",
    "        noise_img_3 = np.array(255*noise_img_3, dtype = 'uint8')\n",
    "        cv2.imwrite(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_noise_1' + '.jpg', noise_img_1)\n",
    "        cv2.imwrite(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_noise_2' + '.jpg', noise_img_2)\n",
    "        cv2.imwrite(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_noise_3' + '.jpg', noise_img_3)\n",
    "\n",
    "        # brightening and darkening\n",
    "        img = Image.open(srs_dir + '/' + str(file))\n",
    "        bright_enhancer = ImageEnhance.Brightness(img)\n",
    "        new_image_1 = bright_enhancer.enhance(random.uniform(1.1, 1.4))\n",
    "        new_image_2 = bright_enhancer.enhance(random.uniform(1.1, 1.4))\n",
    "        new_image_3 = bright_enhancer.enhance(random.uniform(1.1, 1.4))\n",
    "        new_image_1.save(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_bright_1' + '.jpg')\n",
    "        new_image_2.save(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_bright_2' + '.jpg')\n",
    "        new_image_3.save(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_bright_3' + '.jpg')\n",
    "\n",
    "        new_image_4 = bright_enhancer.enhance(random.uniform(0.6, 0.9))\n",
    "        new_image_5 = bright_enhancer.enhance(random.uniform(0.6, 0.9))\n",
    "        new_image_6 = bright_enhancer.enhance(random.uniform(0.6, 0.9))\n",
    "        new_image_4.save(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_dark_1' + '.jpg')\n",
    "        new_image_5.save(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_dark_2' + '.jpg')\n",
    "        new_image_6.save(sub_dst_path_MIX + '/' + str(file).replace('.jpg', '') + '_dark_3' + '.jpg')\n",
    "\n",
    "        shutil.copyfile(srs_dir + '/' + str(file),\n",
    "                        sub_dst_path_MIX + '/' + str(file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix three DA methods\n",
    "\n",
    "Mix: flipping, darkening and adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to store original images and images augmented\n",
    "dst_path_MIX_HV_DARK_NI = r'F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3_DA_MIX_HV_DARK_NI'\n",
    "\n",
    "for folder in folders:\n",
    "    srs_dir = rooter_path + '/' + folder\n",
    "    sub_dst_path_MIX_HV_DARK_NI = dst_path_MIX_HV_DARK_NI + '/' + folder\n",
    "    files = os.listdir(srs_dir)\n",
    "    for file in files:\n",
    "        \n",
    "        img = cv2.imread(srs_dir + '/' + str(file))\n",
    "        \n",
    "        # flipping\n",
    "        hor_ver_img = cv2.flip(img, -1)\n",
    "        cv2.imwrite(sub_dst_path_MIX_HV_DARK_NI + '/' + str(file).replace('.jpg',\n",
    "                    '') + '_hor_ver_flip' + '.jpg', hor_ver_img)\n",
    "        \n",
    "        #  Salt and Pepper noise\n",
    "        noise_img_1 = random_noise(img, mode='s&p', amount=random.uniform(0.01, 0.15))\n",
    "        noise_img_1 = np.array(255*noise_img_1, dtype = 'uint8')\n",
    "        cv2.imwrite(sub_dst_path_MIX_HV_DARK_NI + '/' + str(file).replace('.jpg', '') + '_noise_1' + '.jpg', noise_img_1)\n",
    "        \n",
    "        #  darkening\n",
    "        img = Image.open(srs_dir + '/' + str(file))\n",
    "        bright_enhancer = ImageEnhance.Brightness(img)\n",
    "        # new_image_brightening = bright_enhancer.enhance(random.uniform(1.1, 1.4)) # brightening\n",
    "        new_image_darkening = bright_enhancer.enhance(random.uniform(0.6, 0.9)) # darkening\n",
    "        # new_image_brightening.save(sub_dst_path_MIX_HV_DARK_NI + '/' +\n",
    "        #                  str(file).replace('.jpg', '') + '_bright_1' + '.jpg')\n",
    "        new_image_darkening.save(sub_dst_path_MIX_HV_DARK_NI + '/' + str(file).replace('.jpg', '') + '_dark_1' + '.jpg')\n",
    "\n",
    "        shutil.copyfile(srs_dir + '/' + str(file),\n",
    "                        sub_dst_path_MIX_HV_DARK_NI + '/' + str(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choose images rarandomly and copy them to a new folder\n",
    "\n",
    "# No_copy_images = 145 # the number of images copied to a new folder\n",
    "\n",
    "# src_dir = r\"C:\\Users\\Andre\\Desktop\\Data MSc thesis\\Test data\\test\\test_27m_0deg_center_bank_TEST\\0 - No Plastic\"\n",
    "# dst_dir = r\"C:\\Users\\Andre\\Desktop\\Data MSc thesis\\Test data\\test\\test_27m_0deg_center_bank_VAL\\0 - No Plastic\"\n",
    "\n",
    "# file_list = os.listdir(src_dir)\n",
    "\n",
    "# for i in range(No_copy_images):\n",
    "#     a = random.choice(file_list)\n",
    "#     file_list.remove(a)\n",
    "#     shutil.copy(src_dir + '/' + a, dst_dir + '/' + a)\n",
    "#     os.remove(src_dir + '/' + a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file\n",
    "# with open('file.txt', 'r') as file :\n",
    "#   filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "# filedata = filedata.replace('ram', 'abcd')\n",
    "\n",
    "# Write the file out again\n",
    "# with open('file.txt', 'w') as file:\n",
    "#   file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import matplotlib.pyplot as plt\n",
    "# import requests\n",
    "# import random"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DP_tf_2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
