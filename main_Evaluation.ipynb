{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of models on test sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.miscellaneous import read_config\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils.train_val_test_dataset_import as tvt\n",
    "import utils.evaluation_matrix as em\n",
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 Parse configuration file + initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config files\n",
    "cfg = read_config('./config.yaml')\n",
    "\n",
    "# constants\n",
    "num_classes = cfg['num_classes']\n",
    "image_height = cfg['image_height']\n",
    "image_width = cfg['image_width']\n",
    "batch_size = cfg['batch_size']['tra']\n",
    "\n",
    "labels = cfg['labels']\n",
    "\n",
    "# paths\n",
    "path_test = cfg['Path']['path_test']\n",
    "\n",
    "save_misclassified_images_path = cfg['Path']['save_misclassified_images_path']\n",
    "model_path = cfg['Path']['model_path']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = tvt.import_dataset_test(\n",
    "  path_test, image_height, image_width, batch_size)\n",
    "\n",
    "# autotune\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test = ds_test.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the test DATA\n",
    "\n",
    "for i in range(9):\n",
    "    for image, label_s in ds_test.take(1):  # capture the first batch in tf.dataset\n",
    "      ax = plt.subplot(3, 3, i+1)\n",
    "      image_i = np.uint8(255 * image[i])\n",
    "      plt.imshow(image_i)\n",
    "      plt.title(labels[label_s.numpy()[i]])\n",
    "      plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Evaluation on test sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Statistics output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics output when evaluated on the test data\n",
    " \n",
    "loss, acc = model.evaluate(ds_test)\n",
    "print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.cnn_statistics(model,ds_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.ConfusionMatrix('DenseNet_TL_all_lr_0.0001_1.hdf5', model, ds_test, num_classes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Show and save Misclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate([y for x, y in ds_test], axis=0)\n",
    "y_pred = model.predict(ds_test).argmax(axis=1)\n",
    "x_test = np.concatenate([x for x, y in ds_test], axis=0)\n",
    "# x_test = x_test/255.0\n",
    "misclassified_idx = np.where(y_pred != y_true)[0]\n",
    "print(\"Number of misclassified images: \", misclassified_idx.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclassified_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save misclassified images in one folder\n",
    "\n",
    "\n",
    "for i in misclassified_idx:\n",
    "    fig = plt.figure(figsize=(2.24,2.24)) \n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    x_test[i] = np.uint8(255 * x_test[i])\n",
    "    plt.tight_layout(pad=0) # make the image full image (no padding)\n",
    "    plt.imshow(x_test[i].astype(np.uint8), cmap='gray')\n",
    "    # plt.title(\"%s pred as: %s\" % (labels[y_true[i]], labels[y_pred[i]]))\n",
    "    fig_name = labels[y_true[i]] + \"_pred_as_\" + labels[y_pred[i]] + str(i) + \".jpg\"\n",
    "    fig_path = os.path.join(save_misclassified_images_path,fig_name)\n",
    "    fig.savefig(fig_path)\n",
    "    plt.close() # close the figure, to prevent the figure shows up in Notebook\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one random misclassified example\n",
    "i = np.random.choice(misclassified_idx)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.grid(False)\n",
    "plt.imshow(x_test[i].astype(np.uint8), cmap='gray')\n",
    "plt.title(\"True label: %s, Predicted: %s\" % (labels[y_true[i]], labels[y_pred[i]]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one specific misclassified example\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.grid(False)\n",
    "plt.imshow(x_test[6].astype(np.uint8), cmap='gray')\n",
    "plt.title(\"True label: %s, Predicted: %s\" % (labels[y_true[6]], labels[y_pred[0]]));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DP_tf_2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
