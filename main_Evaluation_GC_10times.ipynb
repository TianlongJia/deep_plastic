{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on the test(validation) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.miscellaneous import read_config\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils.train_val_test_dataset_import_GC as tvt_GC\n",
    "# import utils.train_val_test_dataset_import as tvt\n",
    "import utils.evaluation_matrix as em\n",
    "import utils.write_excel as write_excel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 Parse configuration file + initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config files\n",
    "cfg = read_config('./config.yaml')\n",
    "\n",
    "# constants\n",
    "num_classes = cfg['num_classes']\n",
    "image_height = cfg['image_height']\n",
    "image_width = cfg['image_width']\n",
    "batch_size = cfg['batch_size']['tra']\n",
    "\n",
    "labels = cfg['labels']\n",
    "\n",
    "# paths\n",
    "# path_test = cfg['Path']['path_test']\n",
    "\n",
    "# save_misclassified_images_path = cfg['Path']['save_misclassified_images_path']\n",
    "# model_path = cfg['Path']['model_path']\n",
    "\n",
    "# model_path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp2\\densenet121_TL_all_lr_0.0001_DA_BR.hdf5\"\n",
    "# model_path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Model weights\\densenet121_TL_all_lr_0.0001_train1.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test1=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp1\\Test 1\"\n",
    "path_test2=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Test 2\"\n",
    "path_test3=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Test 3\"\n",
    "path_test4=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Test 4\"\n",
    "path_test5=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Test 5\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test1 = tvt_GC.import_dataset_test(\n",
    "  path_test1, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test1 = ds_test1.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test2 = tvt_GC.import_dataset_test(\n",
    "  path_test2, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test2 = ds_test2.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test3 = tvt_GC.import_dataset_test(\n",
    "  path_test3, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test3 = ds_test3.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test4 = tvt_GC.import_dataset_test(\n",
    "  path_test4, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test4 = ds_test4.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test5 = tvt_GC.import_dataset_test(\n",
    "  path_test5, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test5 = ds_test5.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output test accuaracy of models in one folder\n",
    "excel_path=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp1\\Model_no_rescale_layer\\10_times\\models_exp1.xlsx\"\n",
    "# the folder with weights\n",
    "srs_dir = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp1\\Model_no_rescale_layer\\10_times\\weights\\MobileNet\"\n",
    "\n",
    "\n",
    "model_name_list=[]\n",
    "test1_acc_list=[]\n",
    "test2_acc_list=[]\n",
    "test3_acc_list=[]\n",
    "test4_acc_list=[]\n",
    "test5_acc_list=[]\n",
    "\n",
    "\n",
    "files = os.listdir(srs_dir)\n",
    "for file in files:\n",
    "    print(str(file))\n",
    "    model_name_list.append(file)\n",
    "    model = tf.keras.models.load_model(srs_dir + '/' + str(file))\n",
    "    \n",
    "    loss, acc = model.evaluate(ds_test1)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test1_acc_list.append(acc)\n",
    "\n",
    "    test2_acc_list.append(\"null\")\n",
    "    test3_acc_list.append(\"null\")\n",
    "    test4_acc_list.append(\"null\")\n",
    "    test5_acc_list.append(\"null\")\n",
    "\n",
    "# save results in an excel file\n",
    "write_excel.save_test_results_10_times(excel_path, \"Sheet1\", model_name_list, \n",
    "         test1_acc_list, test2_acc_list, test3_acc_list, test4_acc_list, test5_acc_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outout precision, recall and F1 (tested on Test 1 dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folder with weights\n",
    "srs_dir = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp1\\Model_no_rescale_layer\\10_times\\weights\\test\"\n",
    "\n",
    "files = os.listdir(srs_dir)\n",
    "for file in files:\n",
    "    model = tf.keras.models.load_model(srs_dir + '/' + str(file))\n",
    "    print(file)\n",
    "    em.cnn_statistics(model,ds_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test1 = tvt_GC.import_dataset_test(\n",
    "  path_test1, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test1 = ds_test1.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test2 = tvt_GC.import_dataset_test(\n",
    "  path_test2, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test2 = ds_test2.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test3 = tvt_GC.import_dataset_test(\n",
    "  path_test3, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test3 = ds_test3.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test4 = tvt_GC.import_dataset_test(\n",
    "  path_test4, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test4 = ds_test4.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test5 = tvt_GC.import_dataset_test(\n",
    "  path_test5, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test5 = ds_test5.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output test accuaracy of models in one folder\n",
    "excel_path=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp3\\10_times\\models_exp2.xlsx\"\n",
    "# the folder with weights\n",
    "srs_dir = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp3\\10_times\\weights1\"\n",
    "\n",
    "model_name_list=[]\n",
    "test1_acc_list=[]\n",
    "test2_acc_list=[]\n",
    "test3_acc_list=[]\n",
    "test4_acc_list=[]\n",
    "test5_acc_list=[]\n",
    "\n",
    "\n",
    "files = os.listdir(srs_dir)\n",
    "for file in files:\n",
    "    print(str(file))\n",
    "    model_name_list.append(file)\n",
    "    model = tf.keras.models.load_model(srs_dir + '/' + str(file))\n",
    "    \n",
    "    loss, acc = model.evaluate(ds_test1)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test1_acc_list.append(acc)\n",
    "\n",
    "    loss, acc = model.evaluate(ds_test2)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test2_acc_list.append(acc)\n",
    "    \n",
    "    loss, acc = model.evaluate(ds_test3)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test3_acc_list.append(acc)\n",
    "    \n",
    "    loss, acc = model.evaluate(ds_test4)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test4_acc_list.append(acc)\n",
    "    \n",
    "    loss, acc = model.evaluate(ds_test5)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test5_acc_list.append(acc)\n",
    "    \n",
    "   \n",
    "# save results in an excel file\n",
    "write_excel.save_test_results_10_times(excel_path, \"Sheet1\", model_name_list, \n",
    "         test1_acc_list, test2_acc_list, test3_acc_list, test4_acc_list, test5_acc_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test2 = tvt_GC.import_dataset_test(\n",
    "  path_test2, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test2 = ds_test2.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test3 = tvt_GC.import_dataset_test(\n",
    "  path_test3, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test3 = ds_test3.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test4 = tvt_GC.import_dataset_test(\n",
    "  path_test4, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test4 = ds_test4.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test5 = tvt_GC.import_dataset_test(\n",
    "  path_test5, image_height, image_width, batch_size)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_test5 = ds_test5.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output test accuaracy of models in one folder\n",
    "excel_path=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp3\\10_times\\models_exp3.xlsx\"\n",
    "# the folder with weights\n",
    "srs_dir = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp3\\10_times\\weights\\train3.4\"\n",
    "\n",
    "model_name_list=[]\n",
    "test1_acc_list=[]\n",
    "test2_acc_list=[]\n",
    "test3_acc_list=[]\n",
    "test4_acc_list=[]\n",
    "test5_acc_list=[]\n",
    "\n",
    "\n",
    "files = os.listdir(srs_dir)\n",
    "for file in files:\n",
    "    print(str(file))\n",
    "    model_name_list.append(file)\n",
    "    model = tf.keras.models.load_model(srs_dir + '/' + str(file))\n",
    "    \n",
    "    test1_acc_list.append(\"null\")\n",
    "\n",
    "    loss, acc = model.evaluate(ds_test2)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test2_acc_list.append(acc)\n",
    "    \n",
    "    loss, acc = model.evaluate(ds_test3)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test3_acc_list.append(acc)\n",
    "    \n",
    "    loss, acc = model.evaluate(ds_test4)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test4_acc_list.append(acc)\n",
    "    \n",
    "    loss, acc = model.evaluate(ds_test5)\n",
    "    print(\"Model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    test5_acc_list.append(acc)\n",
    "    \n",
    "\n",
    "    \n",
    "# save results in an excel file\n",
    "write_excel.save_test_results_10_times(excel_path, \"Sheet1\", model_name_list, \n",
    "         test1_acc_list, test2_acc_list, test3_acc_list, test4_acc_list, test5_acc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DP_tf_2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
