{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ece6c554",
   "metadata": {},
   "source": [
    "# Model training\n",
    "Here, models are ResNet50, InceptionV3, DenseNet121, MobileNetV2 and SqueezeNet\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d987147",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39aee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.miscellaneous import read_config\n",
    "from copy import deepcopy\n",
    "\n",
    "import utils.train_val_test_dataset_import as tvt\n",
    "import utils.class_imbalances as ci\n",
    "import utils.plots as plot\n",
    "import models.Models as models\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58d16c",
   "metadata": {},
   "source": [
    "## Parse configuration file + initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config files\n",
    "cfg = read_config('./config.yaml')\n",
    "\n",
    "# constants\n",
    "image_height = cfg['image_height']\n",
    "image_width = cfg['image_width']\n",
    "batch_size = cfg['batch_size']['tra']\n",
    "num_epochs = cfg['trainParams']['num_epochs']\n",
    "lr_rate = cfg['adamParams']['lr']\n",
    "num_classes = cfg['num_classes']\n",
    "\n",
    "# paths\n",
    "path_train = cfg['Path']['path_train']\n",
    "path_val = cfg['Path']['path_val']\n",
    "\n",
    "# load datasets\n",
    "ds_train, ds_val = tvt.import_dataset_train_val(\n",
    "    path_train, path_val, image_height, image_width, batch_size)\n",
    "\n",
    "# autotune\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# class weights\n",
    "class_weights_train = ci.class_weights_4(path_train)\n",
    "\n",
    "# paths to model and checkpoint file save\n",
    "save_model_path_fromscratch = cfg['Path']['save_model_path_fromscratch']\n",
    "save_ckp_path_fromscratch = cfg['Path']['save_ckp_path_fromscratch']\n",
    "save_model_path_TL_classifier = cfg['Path']['save_model_path_TL_classifier']\n",
    "save_ckp_path_TL_classifier = cfg['Path']['save_ckp_path_TL_classifier']\n",
    "save_model_path_TL_all = cfg['Path']['save_model_path_TL_all']\n",
    "save_ckp_path_TL_all = cfg['Path']['save_ckp_path_TL_all']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a456c7d",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bba9d7fa",
   "metadata": {},
   "source": [
    "### (1) Training models from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SqueezeNet\n",
    "r_squeeze = models.SqueezeN(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[1],\n",
    "    save_ckp_path=save_ckp_path_fromscratch[1],\n",
    "    image_height=image_height, image_width=image_width,\n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_squeeze.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet50\n",
    "r_resnet_s = models.ResN50(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[2],\n",
    "     save_ckp_path=save_ckp_path_fromscratch[2],\n",
    "     image_height=image_height, image_width=image_width,\n",
    "     ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_resnet_s.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionV3\n",
    "r_inception_s = models.IncV3(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[3],\n",
    "    save_ckp_path=save_ckp_path_fromscratch[3],\n",
    "    image_height=image_height, image_width=image_width,\n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_inception_s.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e869cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet121\n",
    "r_dense_s = models.DenseN121(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[4],\n",
    "                       save_ckp_path=save_ckp_path_fromscratch[4],\n",
    "                       image_height=image_height, image_width=image_width,\n",
    "                       ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_dense_s.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2\n",
    "r_mobileV2 = models.MNetV2(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[0],\n",
    "   save_ckp_path=save_ckp_path_fromscratch[0],\n",
    "   image_height=image_height, image_width=image_width,\n",
    "   ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_mobileV2.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5684b7b7",
   "metadata": {},
   "source": [
    "### (2) Training models using the FTC strategy\n",
    "pre-train models on ImageNet and then only fine-tune the classifier on the train sets (freeze the Convolutional base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SqueezeNet\n",
    "r_squeeze = models.SqueezeN(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[1], \n",
    "    save_ckp_path=save_ckp_path_TL_classifier[1],\n",
    "    image_height=image_height, image_width=image_width, \n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_squeeze.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c69aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50\n",
    "r_resnet_c = models.ResN50(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[2], \n",
    "     save_ckp_path=save_ckp_path_TL_classifier[2],\n",
    "     image_height=image_height, image_width=image_width, \n",
    "     ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_resnet_c.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d62fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionV3\n",
    "r_inceptionr_c = models.IncV3(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[3], \n",
    "    save_ckp_path=save_ckp_path_TL_classifier[3],\n",
    "    image_height=image_height, image_width=image_width, \n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_inceptionr_c.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef64920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet121\n",
    "r_dense_c = models.DenseN121(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[4], \n",
    "    save_ckp_path=save_ckp_path_TL_classifier[4],\n",
    "    image_height=image_height, image_width=image_width, \n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_dense_c.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a3b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2\n",
    "r_mobileV2 = models.MNetV2(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[0], \n",
    "   save_ckp_path=save_ckp_path_TL_classifier[0],\n",
    "   image_height=image_height, image_width=image_width, \n",
    "   ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_mobileV2.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1c24f80",
   "metadata": {},
   "source": [
    "### (3) Training models using the FTAL strategy\n",
    "pre-train models on ImageNet and fine-tune all layers on train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3769b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SqueezeNet\n",
    "r_squeeze = models.SqueezeN(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[1], \n",
    "    save_ckp_path=save_ckp_path_TL_all[1], \n",
    "    image_height=image_height, image_width=image_width, \n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_squeeze.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be36b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ResNet50\n",
    "r_resnet_a = models.ResN50(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[2], \n",
    "     save_ckp_path=save_ckp_path_TL_all[2], \n",
    "     image_height=image_height, image_width=image_width, \n",
    "     ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_resnet_a.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionV3\n",
    "r_inception_a = models.IncV3(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[3], \n",
    "    save_ckp_path=save_ckp_path_TL_all[3], \n",
    "    image_height=image_height, image_width=image_width, \n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_inception_a.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet121\n",
    "r_dense_a = models.DenseN121(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[4], \n",
    "    save_ckp_path=save_ckp_path_TL_all[4], \n",
    "    image_height=image_height, image_width=image_width, \n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_dense_a.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ee8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2\n",
    "r_mobileV2 = models.MNetV2(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[0], \n",
    "   save_ckp_path=save_ckp_path_TL_all[0], \n",
    "   image_height=image_height, image_width=image_width, \n",
    "   ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_mobileV2.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fda0d1c5",
   "metadata": {},
   "source": [
    "### Plotting accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68216fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model accuracy and loss\n",
    "\n",
    "# plot.plot_hist(hist=r_mobileV2, model_name=\"MobileNetV2\")\n",
    "# plot.plot_hist(hist=r_squeeze, model_name=\"SqueezeNet\")\n",
    "# plot.plot_hist(hist=r_resnet_s, model_name=\"ResNet50\")\n",
    "# plot.plot_hist(hist=r_resnet_c, model_name=\"ResNet50\")\n",
    "# plot.plot_hist(hist=r_resnet_a, model_name=\"ResNet50\")\n",
    "# plot.plot_hist(hist=r_inception_s, model_name='InceptionV3')\n",
    "# plot.plot_hist(hist=r_inceptionr_c, model_name='InceptionV3')\n",
    "# plot.plot_hist(hist=r_inception_a, model_name='InceptionV3')\n",
    "# plot.plot_hist(hist=r_dense_s, model_name=\"DenseNet121\")\n",
    "# plot.plot_hist(hist=r_dense_c, model_name=\"DenseNet121\")\n",
    "# plot.plot_hist(hist=r_dense_a, model_name=\"DenseNet121\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880a097",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tensorboard\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# if the tensorboard page on VS Code is not so clear, \n",
    "# you can type this (localhost:6006) on web browser after executing this code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a5aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DP_tf_2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
