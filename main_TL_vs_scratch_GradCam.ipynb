{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece6c554",
   "metadata": {},
   "source": [
    "# Train the model for further analysis using Grad_Cam\n",
    "Here, models are output without a nested layer structure.\n",
    "\n",
    "The difference between this file and file \"main_TL_vs_Scracth\":\n",
    "\n",
    "(1) In file \"utils.train_val_test_dataset_import_GC\", dataset are rescaled and then put into the model without rescaling layer.\n",
    "\n",
    "(2) In file \"models.TL_models_GC\", model are built without rescaling layer and the pre-trained model (e.g., mobilenetv2_1.00_224) are not nested as a layer named \"mobilenetv2_1.00_224\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d987147",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39aee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.miscellaneous import read_config\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import utils.train_val_test_dataset_import_GC as tvt_GC\n",
    "import utils.class_imbalances as ci\n",
    "import utils.plots as plot\n",
    "import models.TL_models_GC as TL\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58d16c",
   "metadata": {},
   "source": [
    "## Parse configuration file + initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config files\n",
    "cfg = read_config('./config.yaml')\n",
    "\n",
    "# constants\n",
    "image_height = cfg['image_height']\n",
    "image_width = cfg['image_width']\n",
    "batch_size = cfg['batch_size']['tra']\n",
    "num_epochs = cfg['trainParams']['num_epochs']\n",
    "lr_rate = cfg['adamParams']['lr']\n",
    "num_classes = cfg['num_classes']\n",
    "\n",
    "# paths\n",
    "path_train = cfg['Path']['path_train']\n",
    "path_val = cfg['Path']['path_val']\n",
    "\n",
    "# load datasets\n",
    "ds_train, ds_val = tvt_GC.import_dataset_train_val(\n",
    "    path_train, path_val, image_height, image_width, batch_size)\n",
    "\n",
    "# autotune\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# class weights\n",
    "class_weights_train = ci.class_weights_4(path_train)\n",
    "\n",
    "# paths to model and checkpoint file save\n",
    "save_model_path_fromscratch = cfg['Path']['save_model_path_fromscratch']\n",
    "save_ckp_path_fromscratch = cfg['Path']['save_ckp_path_fromscratch']\n",
    "save_model_path_TL_classifier = cfg['Path']['save_model_path_TL_classifier']\n",
    "save_ckp_path_TL_classifier = cfg['Path']['save_ckp_path_TL_classifier']\n",
    "save_model_path_TL_all = cfg['Path']['save_model_path_TL_all']\n",
    "save_ckp_path_TL_all = cfg['Path']['save_ckp_path_TL_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a456c7d",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9d7fa",
   "metadata": {},
   "source": [
    "### (1) Train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "\n",
    "# r_mobileV2 = TL.MNetV2(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[0],\n",
    "#    save_ckp_path=save_ckp_path_fromscratch[0],\n",
    "#    image_height=image_height, image_width=image_width,\n",
    "#    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "#val_acc = r_mobileV2.history['val_accuracy']\n",
    "#print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "\n",
    "#r_squeeze = TL.SqueezeN(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[1],\n",
    " #    save_ckp_path=save_ckp_path_fromscratch[1],\n",
    "   #  image_height=image_height, image_width=image_width,\n",
    "  #   ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "#val_acc = r_squeeze.history['val_accuracy']\n",
    "#print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "\n",
    "\n",
    "# r_resnet_s = TL.ResN50(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[2],\n",
    "#      save_ckp_path=save_ckp_path_fromscratch[2],\n",
    "#      image_height=image_height, image_width=image_width,\n",
    "#      ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "# val_acc = r_resnet_s.history['val_accuracy']\n",
    "# print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "# print(\"lr_rate: \", lr_rate)\n",
    "\n",
    "# lr_rate=0.00001\n",
    "# r_inception_s = TL.IncV3(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[3],\n",
    "#     save_ckp_path=save_ckp_path_fromscratch[3],\n",
    "#     image_height=image_height, image_width=image_width,\n",
    "#     ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "# val_acc = r_inception_s.history['val_accuracy']\n",
    "# print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "# print(\"lr_rate: \", lr_rate)\n",
    "\n",
    "#r_dense_s = TL.DenseN121(num_classes, 'scratch', class_weights=class_weights_train, save_model_path=save_model_path_fromscratch[4],\n",
    " #                       save_ckp_path=save_ckp_path_fromscratch[4],\n",
    "  #                      image_height=image_height, image_width=image_width,\n",
    " #                       ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "#val_acc = r_dense_s.history['val_accuracy']\n",
    "#print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684b7b7",
   "metadata": {},
   "source": [
    "### (2) Transfer learning, fine-tune the classifier\n",
    "pre-trained on ImageNet and only train the classifier (freeze the Convolutional base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad39397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "\n",
    "# r_mobileV2 = TL.MNetV2(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[0], \n",
    "#    save_ckp_path=save_ckp_path_TL_classifier[0],\n",
    "#    image_height=image_height, image_width=image_width, \n",
    "#    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "#val_acc = r_mobileV2.history['val_accuracy']\n",
    "#print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "\n",
    "#r_squeeze = TL.SqueezeN(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[1], \n",
    " #    save_ckp_path=save_ckp_path_TL_classifier[1],\n",
    "  #   image_height=image_height, image_width=image_width, \n",
    "  #   ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "#val_acc = r_squeeze.history['val_accuracy']\n",
    "# print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "\n",
    "# r_resnet_c = TL.ResN50(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[2], \n",
    "#      save_ckp_path=save_ckp_path_TL_classifier[2],\n",
    "#      image_height=image_height, image_width=image_width, \n",
    "#      ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "# val_acc = r_resnet_c.history['val_accuracy']\n",
    "# print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "# print(\"lr_rate: \", lr_rate)\n",
    "\n",
    "# lr_rate=0.00001\n",
    "# r_inceptionr_c = TL.IncV3(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[3], \n",
    "#     save_ckp_path=save_ckp_path_TL_classifier[3],\n",
    "#     image_height=image_height, image_width=image_width, \n",
    "#     ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "# val_acc = r_inceptionr_c.history['val_accuracy']\n",
    "# print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "# print(\"lr_rate: \", lr_rate)\n",
    "\n",
    "#r_dense_c = TL.DenseN121(num_classes, 'TL_classifier', class_weights=class_weights_train, save_model_path=save_model_path_TL_classifier[4], \n",
    " #    save_ckp_path=save_ckp_path_TL_classifier[4],\n",
    "  #   image_height=image_height, image_width=image_width, \n",
    "   #  ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "#val_acc = r_dense_c.history['val_accuracy']\n",
    "#print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c24f80",
   "metadata": {},
   "source": [
    "### (3) Transfer learning, fine-tune all layers\n",
    "pre-trained on ImageNet and fine-tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ee8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "\n",
    "#r_mobileV2 = TL.MNetV2(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[0], \n",
    "#    save_ckp_path=save_ckp_path_TL_all[0], \n",
    "#    image_height=image_height, image_width=image_width, \n",
    "#    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "#val_acc = r_mobileV2.history['val_accuracy']\n",
    "#print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "\n",
    "#r_squeeze = TL.SqueezeN(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[1], \n",
    " #    save_ckp_path=save_ckp_path_TL_all[1], \n",
    "  #   image_height=image_height, image_width=image_width, \n",
    "  #   ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "#val_acc = r_squeeze.history['val_accuracy']\n",
    "#print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "\n",
    "\n",
    "# r_resnet_a = TL.ResN50(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[2], \n",
    "#      save_ckp_path=save_ckp_path_TL_all[2], \n",
    "#      image_height=image_height, image_width=image_width, \n",
    "#      ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "# val_acc = r_resnet_a.history['val_accuracy']\n",
    "# print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "# print(\"lr_rate: \", lr_rate)\n",
    "\n",
    "# lr_rate=0.00001\n",
    "# r_inception_a = TL.IncV3(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[3], \n",
    "#     save_ckp_path=save_ckp_path_TL_all[3], \n",
    "#     image_height=image_height, image_width=image_width, \n",
    "#     ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "# val_acc = r_inception_a.history['val_accuracy']\n",
    "# print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "# print(\"lr_rate: \", lr_rate)\n",
    "\n",
    "lr_rate=0.0001\n",
    "r_dense_a = TL.DenseN121(num_classes, 'TL_all', class_weights=class_weights_train, save_model_path=save_model_path_TL_all[4], \n",
    "    save_ckp_path=save_ckp_path_TL_all[4], \n",
    "    image_height=image_height, image_width=image_width, \n",
    "    ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "val_acc = r_dense_a.history['val_accuracy']\n",
    "print(\"Best Validation Accuracy is\", max(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0d1c5",
   "metadata": {},
   "source": [
    "### Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68216fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model accuracy and loss\n",
    "\n",
    "\n",
    "# plot.plot_hist(hist=r_mobileV2, model_name=\"MobileNetV2\")\n",
    "\n",
    "# plot.plot_hist(hist=r_squeeze, model_name=\"SqueezeNet\")\n",
    "\n",
    "# plot.plot_hist(hist=r_resnet_s, model_name=\"ResNet50\")\n",
    "# plot.plot_hist(hist=r_resnet_c, model_name=\"ResNet50\")\n",
    "# plot.plot_hist(hist=r_resnet_a, model_name=\"ResNet50\")\n",
    "\n",
    "# plot.plot_hist(hist=r_inception_s, model_name='InceptionV3')\n",
    "# plot.plot_hist(hist=r_inceptionr_c, model_name='InceptionV3')\n",
    "# plot.plot_hist(hist=r_inception_a, model_name='InceptionV3')\n",
    "\n",
    "#plot.plot_hist(hist=r_dense_s, model_name=\"DenseNet121\")\n",
    "#plot.plot_hist(hist=r_dense_c, model_name=\"DenseNet121\")\n",
    "plot.plot_hist(hist=r_dense_a, model_name=\"DenseNet121\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880a097",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tensorboard\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# if the tensorboard page on VS Code is not so clear, \n",
    "# you can type this (localhost:6006) on web browser after executing this code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a5aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DP_tf_2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
