{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece6c554",
   "metadata": {},
   "source": [
    "# Train the model for further analysis using Grad_Cam\n",
    "Here, models are output without a nested layer structure.\n",
    "\n",
    "The difference between this file and file \"main_TL_vs_Scracth\":\n",
    "\n",
    "(1) In file \"utils.train_val_test_dataset_import_GC\", dataset are rescaled and then put into the model without rescaling layer.\n",
    "\n",
    "(2) In file \"models.TL_models_GC\", model are built without rescaling layer and the pre-trained model (e.g., mobilenetv2_1.00_224) are not nested as a layer named \"mobilenetv2_1.00_224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39aee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.miscellaneous import read_config\n",
    "from copy import deepcopy\n",
    "\n",
    "import utils.train_val_test_dataset_import_GC as tvt_GC\n",
    "import utils.class_imbalances as ci\n",
    "import utils.plots as plot\n",
    "import models.TL_models_GC as TL\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import utils.write_excel as write_excel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58d16c",
   "metadata": {},
   "source": [
    "## Parse configuration file + initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config files\n",
    "cfg = read_config('./config.yaml')\n",
    "\n",
    "# constants\n",
    "image_height = cfg['image_height']\n",
    "image_width = cfg['image_width']\n",
    "batch_size = cfg['batch_size']['tra']\n",
    "num_epochs = cfg['trainParams']['num_epochs']\n",
    "lr_rate = cfg['adamParams']['lr']\n",
    "num_classes = cfg['num_classes']\n",
    "\n",
    "# paths\n",
    "path_train = cfg['Path']['path_train']\n",
    "path_val = cfg['Path']['path_val']\n",
    "\n",
    "# load datasets\n",
    "ds_train, ds_val = tvt_GC.import_dataset_train_val(\n",
    "    path_train, path_val, image_height, image_width, batch_size)\n",
    "\n",
    "# autotune\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# class weights\n",
    "class_weights_train = ci.class_weights_4(path_train)\n",
    "\n",
    "# paths to model and checkpoint file save\n",
    "save_model_path_fromscratch = cfg['Path']['save_model_path_fromscratch']\n",
    "save_ckp_path_fromscratch = cfg['Path']['save_ckp_path_fromscratch']\n",
    "save_model_path_TL_classifier = cfg['Path']['save_model_path_TL_classifier']\n",
    "save_ckp_path_TL_classifier = cfg['Path']['save_ckp_path_TL_classifier']\n",
    "save_model_path_TL_all = cfg['Path']['save_model_path_TL_all']\n",
    "save_ckp_path_TL_all = cfg['Path']['save_ckp_path_TL_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a456c7d",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9d7fa",
   "metadata": {},
   "source": [
    "### (1) Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_val = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp1\\Validation 1\"\n",
    "\n",
    "# lr_rate_list = [0.0001]\n",
    "lr_rate_list = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "model_arc_list = [\"DenseNet\", \"ResNet\"]\n",
    "# model_arc_list = [\"MobileNet\", \"SqueezeNet\", \"ResNet\", \"Inception\", \"DenseNet\"]\n",
    "fine_tune_strategy_list = [\"TL_all\"]\n",
    "# fine_tune_strategy_list = [\"scratch\", \"TL_classifier\",\"TL_all\"]\n",
    "best_val_acc_list = []\n",
    "training_time_list = []\n",
    "model_name_list = []\n",
    "\n",
    "# path to save weigts\n",
    "path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp1\\Model_no_rescale_layer\\10_times\"\n",
    "# path to save fig\n",
    "fig_path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp1\\Model_no_rescale_layer\\10_times\\fig\"\n",
    "# path to save results in a excel file\n",
    "excel_path=r'F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp1\\Model_no_rescale_layer\\10_times\\models_exp1.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad39397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "repeat_times = 1\n",
    "\n",
    "row_i=1\n",
    "\n",
    "for fine_tune_strategy in fine_tune_strategy_list:\n",
    "  for model_arc_name in model_arc_list:\n",
    "    for lr_rate in lr_rate_list:\n",
    "      for i in range(repeat_times):\n",
    "        model_name = model_arc_name + \"_\" + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + str(i+1) + \".hdf5\"\n",
    "        fig_name_acc = model_arc_name + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + str(i+1) + \"_accuracy.jpg\"\n",
    "        fig_name_loss = model_arc_name + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + str(i+1) + \"_loss.jpg\"\n",
    "        model_name_list.append(model_name)\n",
    "        save_model_path = os.path.join(path,model_name)\n",
    "        save_fig_acc_path = os.path.join(fig_path, fig_name_acc)\n",
    "        save_fig_loss_path = os.path.join(fig_path, fig_name_loss)\n",
    "\n",
    "        starttime = datetime.datetime.now()\n",
    "\n",
    "        if model_arc_name == \"SqueezeNet\":\n",
    "          model_result = TL.SqueezeN(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "             save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "             ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "\n",
    "        if model_arc_name == \"ResNet\":\n",
    "          model_result = TL.ResN50(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "            save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "            ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "\n",
    "        if model_arc_name == \"MobileNet\":\n",
    "          model_result = TL.MNetV2(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "          save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "          ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "\n",
    "        if model_arc_name == \"Inception\":\n",
    "          model_result = TL.IncV3(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "            save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "            ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "\n",
    "        if model_arc_name == \"DenseNet\":\n",
    "          model_result = TL.DenseN121(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "            save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "            ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "\n",
    "        endtime = datetime.datetime.now()\n",
    "\n",
    "        training_time=round((endtime - starttime).seconds/60)\n",
    "        print(\"training_time: \", training_time)\n",
    "        # training_time_list.append(training_time)\n",
    "\n",
    "        val_acc = model_result.history['val_accuracy']\n",
    "        print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "        # best_val_acc_list.append(max(val_acc))\n",
    "        \n",
    "        plot.save_plot_hist(model_result, save_fig_acc_path, save_fig_loss_path)\n",
    "\n",
    "        write_excel.save_train_results_oneByone(row_i, excel_path, \"Sheet1\", \n",
    "          model_name, training_time, max(val_acc))\n",
    "\n",
    "        row_i = row_i+1\n",
    "\n",
    "# write_excel.save_train_results_10_times(excel_path, \"Sheet1\", \n",
    "#           model_name_list, training_time_list, \n",
    "#           best_val_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c24f80",
   "metadata": {},
   "source": [
    "### (2) Experiment 2\n",
    "data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34141ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_times = 10\n",
    "lr_rate = 0.0001\n",
    "model_arc_list = [\"DenseNet\"]\n",
    "# model_arc_list = [\"SqueezeNet\", \"DenseNet\"]\n",
    "fine_tune_strategy = \"TL_all\"\n",
    "train_dataset_list = [\n",
    "    # r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.1-DA HV\"\n",
    "    # r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.2-DA BR\"\n",
    "    # r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.3-DA DARK\"\n",
    "    # r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.4-DA NI\"\n",
    "    r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.5-DA MIX\"\n",
    "]\n",
    "path_val = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp1\\Validation 1\"\n",
    "\n",
    "best_val_acc_list = []\n",
    "training_time_list = []\n",
    "model_name_list = []\n",
    "\n",
    "# path to save weigts\n",
    "path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp2\\10_times\"\n",
    "# path to save fig\n",
    "fig_path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp2\\10_times\\fig\"\n",
    "# path to save results in a excel file\n",
    "excel_path=r'F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp2\\10_times\\models_exp2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ee8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "\n",
    "for train_dataset in train_dataset_list:\n",
    "  path_train = train_dataset\n",
    "  # load datasets\n",
    "  ds_train, ds_val = tvt_GC.import_dataset_train_val(\n",
    "      path_train, path_val, image_height, image_width, batch_size)\n",
    "  # autotune\n",
    "  AUTOTUNE = tf.data.AUTOTUNE\n",
    "  ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "  ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "  \n",
    "  for model_arc_name in model_arc_list:\n",
    "    for i in range(repeat_times):\n",
    "      if train_dataset ==\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.1-DA HV\":\n",
    "        DA_class = \"DA_HV\"\n",
    "      if train_dataset ==\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.2-DA BR\":\n",
    "        DA_class = \"DA_BR\"\n",
    "      if train_dataset ==\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.3-DA DARK\":\n",
    "        DA_class = \"DA_DARK\"\n",
    "      if train_dataset ==\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.4-DA NI\":\n",
    "        DA_class = \"DA_NI\"\n",
    "      if train_dataset ==\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp2\\Train 2.5-DA MIX\":\n",
    "        DA_class = \"DA_MIX\"\n",
    "      \n",
    "      model_name = model_arc_name + \"_\" + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + DA_class + \"_\" + str(i+1) + \".hdf5\"\n",
    "      fig_name_acc = model_arc_name + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + DA_class + \"_\" + str(i+1) + \"_accuracy.jpg\"\n",
    "      fig_name_loss = model_arc_name + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + DA_class + \"_\" + str(i+1) + \"_loss.jpg\"\n",
    "      model_name_list.append(model_name)\n",
    "      save_model_path = os.path.join(path,model_name)\n",
    "      save_fig_acc_path = os.path.join(fig_path, fig_name_acc)\n",
    "      save_fig_loss_path = os.path.join(fig_path, fig_name_loss)\n",
    "\n",
    "      starttime = datetime.datetime.now()\n",
    "\n",
    "      if model_arc_name == \"SqueezeNet\":\n",
    "        model_result = TL.SqueezeN(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "            save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "            ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "      if model_arc_name == \"DenseNet\":\n",
    "        model_result = TL.DenseN121(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "            save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "            ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "      \n",
    "      endtime = datetime.datetime.now()\n",
    "      training_time=round((endtime - starttime).seconds/60)\n",
    "      print(\"training_time: \", training_time)\n",
    "      training_time_list.append(training_time)\n",
    "      val_acc = model_result.history['val_accuracy']\n",
    "      print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "      best_val_acc_list.append(max(val_acc))\n",
    "      plot.save_plot_hist(model_result, save_fig_acc_path, save_fig_loss_path)\n",
    "\n",
    "write_excel.save_train_results_10_times(excel_path, \"Sheet1\", \n",
    "          model_name_list, training_time_list, \n",
    "          best_val_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b10a12",
   "metadata": {},
   "source": [
    "### (3) Experiment 3\n",
    "\n",
    "1. adding images\n",
    "\n",
    "2. adding images_DA_MIX\n",
    "\n",
    "3. all images_DA_MIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf251f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rate = 0.0001\n",
    "model_arc_list = [\"DenseNet\"]\n",
    "# model_arc_list = [\"SqueezeNet\", \"DenseNet\"]\n",
    "fine_tune_strategy = \"TL_all\"\n",
    "train_dataset_list = [\n",
    "    # r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.1-adding_images\",\n",
    "    # r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.2_adding_images_with_DA_MIX\",\n",
    "    # r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.3_all_images_with_DA_MIX\",\n",
    "    r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.4-ANI_DA_HV_ALL\"\n",
    "]\n",
    "path_val = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Validation 2\"\n",
    "\n",
    "best_val_acc_list = []\n",
    "training_time_list = []\n",
    "model_name_list = []\n",
    "\n",
    "# path to save weigts\n",
    "path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp3\\10_times\"\n",
    "# path to save fig\n",
    "fig_path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp3\\10_times\\fig\"\n",
    "# path to save results in a excel file\n",
    "excel_path=r'F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp3\\10_times\\models_exp3.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "repeat_times = 9\n",
    "\n",
    "row_i=1\n",
    "\n",
    "\n",
    "for train_dataset in train_dataset_list:\n",
    "  path_train = train_dataset\n",
    "  # load datasets\n",
    "  ds_train, ds_val = tvt_GC.import_dataset_train_val(\n",
    "      path_train, path_val, image_height, image_width, batch_size)\n",
    "  # autotune\n",
    "  AUTOTUNE = tf.data.AUTOTUNE\n",
    "  ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "  ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "  \n",
    "  for model_arc_name in model_arc_list:\n",
    "    for i in range(repeat_times):\n",
    "      if train_dataset == \"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.1-adding_images\":\n",
    "        train_class = \"train3.1\"\n",
    "      if train_dataset == \"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.2_adding_images_with_DA_MIX\":\n",
    "        train_class = \"train3.2\"\n",
    "      if train_dataset ==\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.3_all_images_with_DA_MIX\":\n",
    "        train_class = \"train3.3\"\n",
    "      if train_dataset ==\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3.4-ANI_DA_HV_ALL\":\n",
    "        train_class = \"train3.4\"\n",
    "\n",
    "      \n",
    "      model_name = model_arc_name + \"_\" + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + train_class + \"_\" + str(i+1) + \".hdf5\"\n",
    "      fig_name_acc = model_arc_name + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + train_class + \"_\" + str(i+1) + \"_accuracy.jpg\"\n",
    "      fig_name_loss = model_arc_name + fine_tune_strategy +\"_lr_\" + str(lr_rate) + \"_\" + train_class + \"_\" + str(i+1) + \"_loss.jpg\"\n",
    "      model_name_list.append(model_name)\n",
    "      save_model_path = os.path.join(path,model_name)\n",
    "      save_fig_acc_path = os.path.join(fig_path, fig_name_acc)\n",
    "      save_fig_loss_path = os.path.join(fig_path, fig_name_loss)\n",
    "\n",
    "      starttime = datetime.datetime.now()\n",
    "\n",
    "      if model_arc_name == \"SqueezeNet\":\n",
    "        model_result = TL.SqueezeN(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "            save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "            ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "      if model_arc_name == \"DenseNet\":\n",
    "        model_result = TL.DenseN121(num_classes, fine_tune_strategy, class_weights=class_weights_train, save_model_path=save_model_path, \n",
    "            save_ckp_path=None, image_height=image_height, image_width=image_width,\n",
    "            ds_train=ds_train, ds_val=ds_val, lr_rate=lr_rate, num_epochs=num_epochs)\n",
    "      \n",
    "      endtime = datetime.datetime.now()\n",
    "      training_time=round((endtime - starttime).seconds/60)\n",
    "      print(\"training_time: \", training_time)\n",
    "      # training_time_list.append(training_time)\n",
    "      \n",
    "      val_acc = model_result.history['val_accuracy']\n",
    "      print(\"Best Validation Accuracy is\", max(val_acc))\n",
    "      # best_val_acc_list.append(max(val_acc))\n",
    "      \n",
    "      plot.save_plot_hist(model_result, save_fig_acc_path, save_fig_loss_path)\n",
    "\n",
    "      write_excel.save_train_results_oneByone(row_i, excel_path, \"Sheet1\", \n",
    "          model_name, training_time, max(val_acc))\n",
    "      \n",
    "      row_i = row_i+1\n",
    "\n",
    "# write_excel.save_train_results_10_times(excel_path, \"Sheet1\", \n",
    "#           model_name_list, training_time_list, \n",
    "#           best_val_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880a097",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tensorboard\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# if the tensorboard page on VS Code is not so clear, \n",
    "# you can type this (localhost:6006) on web browser after executing this code "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DP_tf_2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
