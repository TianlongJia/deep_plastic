{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Grad-cam_image_dataset_from_directory\n",
        "Show the heatmap for test data(multiple images). After saving the heatmaps in one folder, we should select and analyze the misclassified images and delete the else images manually.\n",
        "\n",
        "Read images method: image_dataset_from_directory()\n",
        "\n",
        "https://colab.research.google.com/github/Engineer1999/Chest-X-ray-classification-with-GradCAM/blob/main/Chest_X_ray_classification_using_Transfer_Learning_and_GradCAM_for_transparency.ipynb#scrollTo=snc0-2dk0q-d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H9iMdy_t_JE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from collections import Counter\n",
        "import os\n",
        "from miscellaneous import read_config\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import train_val_test_dataset_import_GC as tvt_GC\n",
        "import evaluation_matrix as em\n",
        "\n",
        "import Grad_cam as grad_cam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parse configuration file + initializations\n",
        "\n",
        "\"batch_size\" should be more than \"No_images\" for output gradcam results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read config files\n",
        "main_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
        "config_path= os.path.join(main_path,'config.yaml')\n",
        "cfg = read_config(config_path)\n",
        "\n",
        "\n",
        "# constants\n",
        "image_height = cfg['image_height']\n",
        "image_width = cfg['image_width']\n",
        "# batch_size = cfg['batch_size']['tst']\n",
        "batch_size = 700\n",
        "print(\"batch_size for test: \",batch_size)\n",
        "labels = cfg['labels']\n",
        "\n",
        "# paths\n",
        "# path_test = cfg['Path']['path_test']\n",
        "\n",
        "save_gradcam_result_path = cfg['Path']['save_gradcam_result_path']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_test = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp1\\Test 1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folders = os.listdir(path_test)\n",
        "No_images = 0\n",
        "\n",
        "for folder in folders:\n",
        "    dir = path_test + '/' + str(folder)\n",
        "    files = os.listdir(dir)\n",
        "    No_images = No_images + files.__len__()\n",
        "print(\"No_images: \", No_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if batch_size < No_images:\n",
        "  print(\"Batch_size should be more than/equal No_images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYMgyyWZz7vk",
        "outputId": "d422430d-2faf-4a25-ab4d-22aa14d561fe"
      },
      "outputs": [],
      "source": [
        "# load test datasets\n",
        "ds_test = tvt_GC.import_dataset_test(\n",
        "    path_test, image_height, image_width, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ds_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Capture images from tf.dataset\n",
        "\n",
        "for i in range(2):\n",
        "    for image, label in ds_test.take(1):  # capture the first batch in tf.dataset\n",
        "      ax = plt.subplot(3, 3, i+1)\n",
        "      image_i = np.uint8(255 * image[i])\n",
        "      plt.imshow(image_i)\n",
        "      plt.title(labels[label.numpy()[i]])\n",
        "      plt.axis('off')\n",
        "\n",
        "# batch should be more than 9, otherwise it will report error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD4IAcM2C6Ow"
      },
      "outputs": [],
      "source": [
        "# load DenseNet_TL_all_lr_0.0001\n",
        "model_path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp1\\Model_no_rescale_layer\\densenet121_TL_all_lr_0.0001_train1.hdf5\"\n",
        "\n",
        "# load SqueezeNet_TL_all_lr_0.0001\n",
        "# model_path = r\"F:\\Tianlong\\Data\\Deep_Plastic\\Results\\Exp1\\Model_no_rescale_layer\\SqueezeNet_TL_all_lr_0.0001_train1.hdf5\"\n",
        "\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "# model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15ub6QQeh1C6"
      },
      "outputs": [],
      "source": [
        "# Predict the one sample in test data\n",
        "\n",
        "# out_put = model.predict(np.expand_dims(image[0], axis=0))\n",
        "# print (\"predicted as: \", labels[np.argmax(out_put)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define model layer for gradcam\n",
        "\n",
        "Notice: \"classifier_layer_names\" should include all the layers on the top of  \"last_conv_layer_name\". Another way of saying it, \"classifier_layer_names\" and \"last_conv_layer_name\" should include all layers of model, and not overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1ZHEROH1Pkj"
      },
      "outputs": [],
      "source": [
        "# DenseNet\n",
        "\n",
        "last_conv_layer_name = \"bn\"\n",
        "classifier_layer_names = [\n",
        "    # \"conv5_block16_concat\",\n",
        "    # \"bn\",\n",
        "    \"relu\",\n",
        "    \"global_average_pooling2d\",\n",
        "    \"dense\"\n",
        "]\n",
        "\n",
        "# # Squeeze\n",
        "# last_conv_layer_name = \"conv10\"\n",
        "# classifier_layer_names = [\n",
        "#     \"global_average_pooling2d\",\n",
        "#     \"dense\"\n",
        "# ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show heatmap and save it in one folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# capture the first batch and show images\n",
        "# Here \"batch_size\" should be over \"No_images\", otherwise it will report an error \n",
        "\n",
        "for i in range(No_images):\n",
        "    heatmap, top_index = grad_cam.make_gradcam_heatmap(np.expand_dims(\n",
        "        image[i], axis=0), model, last_conv_layer_name, classifier_layer_names)\n",
        "    # print(heatmap.shape)\n",
        "    # img = np.uint8(255 * image[i])\n",
        "    img = np.uint8(255 * image[i])\n",
        "    output = grad_cam.superimposed_img(img, heatmap, image_height, image_width)\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
        "    # plt.axis('off')\n",
        "    ax[0].imshow(heatmap)\n",
        "    ax[1].imshow(img)\n",
        "    ax[2].imshow(output)\n",
        "    plt.suptitle(labels[label.numpy()[i]] +\n",
        "              \" pred as: \" + labels[top_index], fontsize=8)\n",
        "    # plt.show()\n",
        "\n",
        "    fig_name = labels[label.numpy()[i]] + \"_Pred_As_\" + labels[top_index] + \"_\" +str(i) + \".jpg\"\n",
        "    fig_path = os.path.join(save_gradcam_result_path,fig_name)\n",
        "    fig.savefig(fig_path)\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chest X-ray classification using Transfer Learning and GradCAM for transparency ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('DP_tf_2.6')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
