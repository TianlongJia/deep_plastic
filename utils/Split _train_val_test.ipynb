{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into three sets (train, validation, and test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Split folders with files (e.g. images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split folders with files (e.g. images) into training, validation and test (dataset) folders.\n",
    "# reference:\n",
    "#      https://medium.com/nerd-for-tech/easily-split-your-directory-into-train-validation-and-testing-format-f1359f34dd93\n",
    "\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "input_directory=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3_Val 2 (not all data)\\train_all_exc_27m_0deg\"\n",
    "\n",
    "output_directory=r\"F:\\Tianlong\\Data\\Deep_Plastic\\Data\\Exp3\\Train 3_Val 2 (not all data)\\split\"\n",
    "\n",
    "splitfolders.ratio(input_directory, # The location of dataset\n",
    "                   output=output_directory, # The output location\n",
    "                   seed=42, # The number of seed\n",
    "                  #  ratio=(.8, .2), # The ratio of splited dataset\n",
    "                   ratio=(.8, .1, .1), # The ratio of splited dataset\n",
    "                   group_prefix=None, # If your dataset contains more than one file like \".jpg\", \".pdf\", etc\n",
    "                   move=False # If you choose to move, turn this into True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Split CSV file (Not yet used and tested?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference:\n",
    "#    https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/bluebook-for-bulldozers/TrainAndValid.csv', parse_dates=['saledate'], low_memory=False)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "X = df.drop(columns = ['SalePrice']).copy()\n",
    "y = df['SalePrice']\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DP_tf_2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
