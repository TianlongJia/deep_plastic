{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model architecture of SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.imagenet_utils import obtain_input_shape\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import get_source_inputs\n",
    "from tensorflow.keras.utils import get_file\n",
    "from keras.utils import layer_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "WEIGHTS_PATH = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "WEIGHTS_PATH_NO_TOP = \"https://github.com/rcmalli/keras-squeezenet/releases/download/v1.0/squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Modular function for Fire Node\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "\n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "# Original SqueezeNet from paper.\n",
    "\n",
    "def SqueezeNet(include_top=True, weights='imagenet',\n",
    "                input_tensor=None, input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    \"\"\"Instantiates the SqueezeNet architecture.\n",
    "     \"\"\"\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                        '`None` (random initialization) or `imagenet` '\n",
    "                        '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                             ' as true, `classes` should be 1000')\n",
    "\n",
    "    input_shape = obtain_input_shape(input_shape,\n",
    "                                          default_size=227,\n",
    "                                          min_size=48,\n",
    "                                          data_format=K.image_data_format(),\n",
    "                                          require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "\n",
    "    if include_top:\n",
    "        # It's not obvious where to cut the network...\n",
    "        # Could do the 8th or 9th layer... some work recommends cutting earlier layers.\n",
    "\n",
    "        x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "        x = Activation('relu', name='relu_conv10')(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Activation('softmax', name='loss')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "        elif pooling == None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Unknown argument for 'pooling'=\" + pooling)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name='squeezenet')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                        WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models')\n",
    "\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height=224\n",
    "image_width=224\n",
    "batch_size=16\n",
    "nr_epochs=50\n",
    "\n",
    "SqueezeNet_model = SqueezeNet(input_shape=(image_height, image_width, 3), include_top=False, weights=None)\n",
    "SqueezeNet_model.trainable = True\n",
    "\n",
    "SqueezeNet_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('DP_tf_2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02a9bb87e7ed71d24a2ebc89c433b3cf6535eba82982e54a30fa825081488b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
